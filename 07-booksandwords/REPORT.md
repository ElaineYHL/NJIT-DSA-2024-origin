1. The hash function I implemented used arithmetic on keys, combined with shifts and multiplications. For each character, the current hash value is multiplied by 31 and then the ASCII value of the character is added. 
2. The heapSort method is used to sort the array of nodes according to the count field of the node. The fillArray method is used to fill the array of nodes in the binary search tree in the order of inorder traversal, and the heapSort method is used to sort the filled array. We also use the heapify method to maintain the top-100 elements. The find method of the root node recursively searches the tree for the key and returns the value associated with the key
3. When it comes to implementation correctness, I make sure that all operations adhere to the specified requirements and properties of the data structure. In the case of a bst, this means ensuring that the left subtree of a node only contains nodes with keys smaller than the key, and the right subtree only contains nodes with keys larger than the key. For hash tables, this means ensuring that collisions are handled correctly and that the hash function distributes keys evenly among buckets. Bugs are carefully analyzed to understand the root cause. Reasons for the bug might include logical errors in the implementation or boundary conditions not being handled correctly. Solutions include debugging the code, adding tests to cover problematic areas, and refactoring the code if necessary.
4. The time complexity of my implementation depends on the particular operation being performed. The average insert, delete, and search time for a BST is O(log n). Getting the top-100 list requires traversing the tree (O(n)) and then sorting (usually O(n log n) for comparison-based sorting algorithms). For hash tables, insert, delete, and search times are typically O(1) on average. But in the worst case, when the number of collisions is large, the time complexity of the algorithm can be reduced to O(n). 
How efficiently the code reads and manages words and their counts depends on how efficiently these data structures are implemented and how they interact with each other.
I used a heapsort method to sort the array of nodes based on their count field. Its optimal time complexity is O(nlogn), its average time complexity is O(nlogn), and its worst time complexity is O(nlogn).
5. Perhaps the hardest things to understand and implement in this programming task have to do with the specific challenges posed by the data structures and algorithms involved, as well as the need to comply with various testing requirements.
6. Through this programming task, I could learn the pros and cons of different data structures and algorithms. I will have a deeper understanding of how to implement and optimize these structures to meet specific performance requirements. Also, I can improve my debugging skills by identifying and fixing issues in my code.
